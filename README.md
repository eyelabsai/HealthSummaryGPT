# WhisperTranscription

A minimal Node.js service that records audio via the browser, transcribes speech using OpenAI‚Äôs `gpt-4o-mini-transcribe`, then‚Äîon demand‚Äîsummarises the transcript with `gpt-4o-mini`.  

## Overview  
This application provides:  
1. A simple front end (HTML/JavaScript) that captures microphone input and uploads it as a WebM blob.  
2. An Express-powered back end that:  
   - Converts the browser-generated WebM to WAV (via `ffmpeg`).  
   - Streams the resulting WAV to OpenAI‚Äôs transcription endpoint.  
   - Returns the transcript to the browser.  
   - Accepts a transcript and returns a concise summary via the LLM.  

You can record your voice, obtain a transcription, then click ‚ÄúSummarise‚Äù to receive a condensed version.  

## Prerequisites  
- **Node.js** (v16 or later) and **npm** installed.  
- **ffmpeg** installed on your system (Homebrew, apt, etc.), so that the WebM‚ÜíWAV conversion works.  
- An **OpenAI API key** with access to the `gpt-4o-mini-transcribe` and `gpt-4o-mini` models.  

## Installation  

1. **Clone the repository** (or copy files) into a local folder:  
   ```bash
   git clone https://github.com/eyelabsai/WhisperTranscription.git
   cd WhisperTranscription
   ```

2.	Install Node.js dependencies:
```
npm install
```
3.	Install ffmpeg (if not already):

macOS (Homebrew):
```
brew install ffmpeg
```

Ubuntu/Debian:
```
sudo apt update
sudo apt install ffmpeg
```

Confirm installation with:
```
ffmpeg -version
```

4. Configure environment variables:
Create a file named `.env` in the project root with:

```
OPENAI_API_KEY=sk-YOUR_OPENAI_KEY_HERE
```

Ensure that the key is valid and grants access to both gpt-4o-mini-transcribe and gpt-4o-mini.


## Usage

1. Start the server:

```
node server.js
```

You should see:
```
Server listening on port 3000
```

2. Open your browser at
```
http://localhost:3000
```

‚Äì You will see a page with ‚ÄúStart Recording‚Äù / ‚ÄúStop Recording‚Äù buttons.

3. Record & transcribe:

Click ‚Äúüé§ Start Recording‚Äù, speak into your microphone, then click ‚Äú‚èπ Stop Recording‚Äù. Once complete, the raw transcript appears in the first textarea.

4. Summarize:

Click ‚ÄúüìÑ Summarize Transcript‚Äù.

The transcript is sent to the server, which calls gpt-4o-mini to produce a concise summary. The summary is displayed in the second textarea.

Endpoints

POST /transcribe
	‚Ä¢	Content-Type: multipart/form-data
	‚Ä¢	Form Field:
	‚Ä¢	audio (file): Browser-recorded audio blob (WebM).

Response (JSON):

{ 
  "success": true, 
  "transcript": "‚Ä¶your transcribed text‚Ä¶" 
}

Or, on failure:

{ 
  "success": false, 
  "error": "Transcription failed." 
}

POST /summarise
	‚Ä¢	Content-Type: application/json
	‚Ä¢	JSON Body:

{ 
  "transcript": "‚Ä¶full transcript text‚Ä¶" 
}

Response (JSON):

{ 
  "success": true, 
  "summary": "‚Ä¶concise summary‚Ä¶" 
}

Or, on failure:

{ 
  "success": false, 
  "error": "Summarisation failed." 
}
