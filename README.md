# WhisperTranscription

A minimal Node.js service that records audio via the browser, transcribes speech using OpenAIâ€™s `gpt-4o-mini-transcribe`, thenâ€”on demandâ€”summarises the transcript with `gpt-4o-mini`.  

## Overview  
This application provides:  
1. A simple front end (HTML/JavaScript) that captures microphone input and uploads it as a WebM blob.  
2. An Express-powered back end that:  
   - Converts the browser-generated WebM to WAV (via `ffmpeg`).  
   - Streams the resulting WAV to OpenAIâ€™s transcription endpoint.  
   - Returns the transcript to the browser.  
   - Accepts a transcript and returns a concise summary via the LLM.  

You can record your voice, obtain a transcription, then click â€œSummariseâ€ to receive a condensed version.  

## Prerequisites  
- **Node.js** (v16 or later) and **npm** installed.  
- **ffmpeg** installed on your system (Homebrew, apt, etc.), so that the WebMâ†’WAV conversion works.  
- An **OpenAI API key** with access to the `gpt-4o-mini-transcribe` and `gpt-4o-mini` models.  

## Installation  

1. **Clone the repository** (or copy files) into a local folder:  
   ```bash
   git clone https://github.com/your-username/WhisperTranscription.git
   cd WhisperTranscription
   ```

2.	Install Node.js dependencies:
```
npm install
```
3.	Install ffmpeg (if not already):

macOS (Homebrew):
```
brew install ffmpeg
```

Ubuntu/Debian:
```
sudo apt update
sudo apt install ffmpeg
```

Confirm installation with:
```
ffmpeg -version
```

4. Configure environment variables:
Create a file named `.env` in the project root with:

```
OPENAI_API_KEY=sk-YOUR_OPENAI_KEY_HERE
```

Ensure that the key is valid and grants access to both gpt-4o-mini-transcribe and gpt-4o-mini.

Project Structure

.
â”œâ”€â”€ public
â”‚   â””â”€â”€ index.html           â† Front-end HTML/JS for recording, transcription, summarisation
â”œâ”€â”€ uploads                  â† Multerâ€™s temporary storage for incoming audio blobs
â”œâ”€â”€ server.js                â† Main Express server
â”œâ”€â”€ package.json
â””â”€â”€ .env                     â† Contains your OpenAI API key (not committed to Git)


## Usage

1. Start the server:

```
node server.js
```

You should see:
```
Server listening on port 3000
```

2. Open your browser at
```
http://localhost:3000
```

â€“ You will see a page with â€œStart Recordingâ€ / â€œStop Recordingâ€ buttons.

3. Record & transcribe:

Click â€œğŸ¤ Start Recordingâ€, speak into your microphone, then click â€œâ¹ Stop Recordingâ€. Once complete, the raw transcript appears in the first textarea.

4. Summarize:

Click â€œğŸ“„ Summarize Transcriptâ€.

The transcript is sent to the server, which calls gpt-4o-mini to produce a concise summary. The summary is displayed in the second textarea.

Endpoints

POST /transcribe
	â€¢	Content-Type: multipart/form-data
	â€¢	Form Field:
	â€¢	audio (file): Browser-recorded audio blob (WebM).

Response (JSON):

{ 
  "success": true, 
  "transcript": "â€¦your transcribed textâ€¦" 
}

Or, on failure:

{ 
  "success": false, 
  "error": "Transcription failed." 
}

POST /summarise
	â€¢	Content-Type: application/json
	â€¢	JSON Body:

{ 
  "transcript": "â€¦full transcript textâ€¦" 
}

Response (JSON):

{ 
  "success": true, 
  "summary": "â€¦concise summaryâ€¦" 
}

Or, on failure:

{ 
  "success": false, 
  "error": "Summarisation failed." 
}
